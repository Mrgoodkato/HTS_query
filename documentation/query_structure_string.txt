OVERVIEW:

DONE IN string_query_db script:------------------------------------------------------

When handling a string query to the database, there are several things that should happen in order to provide the best results possible against the information already present in the DB.

Let's breakdown the steps:

1) There are several ways the query string can be input by the user:

    -Single word
    -Multiple words
    -Multiple or single word with special characters
    -Number
    -Multiple or single word with numbers

    For each of these scenarios we need to first process the string to be divided into a list of strings to grab and query individually in the DB.

    To do this we will use a series of functions to parse the query string and create a list with single words in lowercase, including numbers.

    Example:
    "query = 'words words2 words##, words'

    def parseQuery(query):

        return ['words', 'words2', 'words', 'words']"

    
2) When we get the list of keywords separated, each word will be queried against the string_dict collection using the find({'string':<query>}) method from pymongo.

This will provide a list of ObjectIDs from Mongo referencing the hts_record entries where each word has a coincidence.

We will store each of the ObjectID lists for each of the words in a dict for subsequent processing as follows:

result = [
    {
        'string': <query>,
        'records': [<ObjectIDs>...]
    },
    {
        'string': <query>,
        'records': [<ObjectIDs>...]
    }
]

3) After that we will process the list of objects gathered with the ObjectIDs and start the process of organizing what IDs are repeating between those dictionaries.

4) When we have the IDs organized by the most repeated to the ones less repeated we continue by querying each of the top IDs (we can set a rule for a top 5 IDs to not clutter the query) and gathering each hts_record info for each ID.

5) When we have each hts_record for each ID in order, we will proceed to internally traverse each record with the words available to get the inner_records that have the coincidences.

WORK ON string_query_processing script--------------------------------------------------

6) Then we organize the results by the highest number of matches for the most words to the lowest number of matches for the least words.

7) From the result of the query, which will be a dictionary comprised of the chapter data, and keys referring to each chapter retrieved:
    {
        <CHAPTER_NAME1>: {
            'coincidence': <NUMBER_OF_COINCIDENCES>,
            'keyword': [<STRINGS_FROM QUERY_MATCHED>...]
            'data': [<CHAPTER_DATA>...]
        },
        <CHAPTER_NAME2>: {
            'coincidence': <NUMBER_OF_COINCIDENCES>,
            'keyword': [<STRINGS_FROM QUERY_MATCHED>...]
            'data': [<CHAPTER_DATA>...]
        },
        {
            ...
        }
    }

    We import this dictionary and process it to parse only the relevant chapter data pertaining to the 'keyword' array of words with the following logic:

    1A) For each string we search the 'data' array in the description and grab all results that have that string in the 'description' key into a list:

        [<SUBCHAPTER1>, <SUBCHATPER2>, ...]
   
    2A) This list will have possibly repeated values because there might be strings that are in the same description key of the original data. So we need to remove all duplicates from the list, but we need to do it counting the number of times a duplicate is found to create hierarchy, gathering an object like this:

        [
            (<SUBCHAPTER1>, <OCURRENCES>), (<SUBCHATPER2>, <OCURRENCES>), ...
        ]

        This object will contain the SUBCHAPTER string and the Number of Ocurrences of that subchapter according to the repeated results from the previous list.

        This list will be organized by the higher number of ocurrences to the lowest.

    3A) From here we can then generate a more complex object that will be the result of parsing the subchapter numbers and grabbing all related subchapter information to generate a more in depth result for the user to view. > THIS IS STILL IN PROCESS OF WORK.


    