{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains all the code for creating the HTS and string_dict files in the temp folder for further addition to the MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_words = [\"a\",\"about\",\"above\",\"after\",\"again\",\"against\",\"all\",\"am\",\"an\",\"and\",\"any\",\"are\",\"aren't\",\"as\",\"at\",\"be\",\"because\",\"been\",\"before\",\"being\",\"below\",\"between\",\"both\",\"but\",\"by\",\"can't\",\"cannot\",\"could\",\"couldn't\",\"did\",\"didn't\",\"do\",\"does\",\"doesn't\",\"doing\",\"don't\",\"down\",\"during\",\"each\",\"few\",\"for\",\"from\",\"further\",\"had\",\"hadn't\",\"has\",\"hasn't\",\"have\",\"haven't\",\"having\",\"he\",\"he'd\",\"he'll\",\"he's\",\"her\",\"here\",\"here's\",\"hers\",\"herself\",\"him\",\"himself\",\"his\",\"how\",\"how's\",\"i\",\"i'd\",\"i'll\",\"i'm\",\"i've\",\"if\",\"in\",\"into\",\"is\",\"isn't\",\"it\",\"it's\",\"its\",\"itself\",\"let's\",\"me\",\"more\",\"most\",\"mustn't\",\"my\",\"myself\",\"no\",\"nor\",\"not\",\"of\",\"off\",\"on\",\"once\",\"only\",\"or\",\"other\",\"ought\",\"our\",\"ours\",\"ourselves\",\"out\",\"over\",\"own\",\"same\",\"shan't\",\"she\",\"she'd\",\"she'll\",\"she's\",\"should\",\"shouldn't\",\"so\",\"some\",\"such\",\"than\",\"that\",\"that's\",\"the\",\"their\",\"theirs\",\"them\",\"themselves\",\"then\",\"there\",\"there's\",\"these\",\"they\",\"they'd\",\"they'll\",\"they're\",\"they've\",\"this\",\"those\",\"through\",\"to\",\"too\",\"under\",\"until\",\"up\",\"very\",\"was\",\"wasn't\",\"we\",\"we'd\",\"we'll\",\"we're\",\"we've\",\"were\",\"weren't\",\"what\",\"what's\",\"when\",\"when's\",\"where\",\"where's\",\"which\",\"while\",\"who\",\"who's\",\"whom\",\"why\",\"why's\",\"with\",\"won't\",\"would\",\"wouldn't\",\"you\",\"you'd\",\"you'll\",\"you're\",\"you've\",\"your\",\"yours\",\"yourself\",\"yourselves\"]\n",
    "\n",
    "punctuation_pattern = r'[!\\\"#$%&\\'()*+,-./:;<=>?@\\[\\]\\^_`{|}~â€”]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "\n",
    "def addRowsToDataframe(df: pd.DataFrame, row: list):\n",
    "    \"\"\"Helper method used to easily add new rows to a pandas dataframe\n",
    "\n",
    "    Args:\n",
    "        df: pandas.DataFrame\n",
    "            DataFrame to add the new rows to\n",
    "        row (list): List to be added as a row into the dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    df.loc[len(df)] = row\n",
    "\n",
    "def checkKeyWords(string: str):\n",
    "    \"\"\"Checks against the keywords list for any matches in the string input\n",
    "\n",
    "    Args:\n",
    "        string (str): String that will be checked\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the string does not coincide with the list, False if there is a match\n",
    "    \"\"\"\n",
    "\n",
    "    for keyword in key_words:\n",
    "        match = re.search(rf'^{keyword}$', string=string)\n",
    "        if(match):\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def openJSON(path: str):\n",
    "    \"\"\"Function that opens a JSON file and returns that file as a list\n",
    "\n",
    "    Args:\n",
    "        path (str): Path to the JSON file\n",
    "\n",
    "    Returns:\n",
    "        list: Returns a list object with the JSON information\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path, 'r') as file:\n",
    "        result = json.loads(file.read())\n",
    "    \n",
    "    return result\n",
    "\n",
    "def processRecord(record: list):\n",
    "    \"\"\"Helper method that works by iterating each JSON HTS record already processed, and eliminates the empty htsno records, adding their description to the next sections following the indent logic\n",
    "\n",
    "    Args:\n",
    "        record (list): JSON processed list containing several sections to be iterated\n",
    "    \n",
    "    Returns:\n",
    "        list: Returns the resulting sections in a list without the empty htsno sections and correctly appeding the descriptions of empty htsno sections to their corresponding sections. \n",
    "    \"\"\"\n",
    "\n",
    "    result = []\n",
    "    saved_section_description = {\n",
    "        'description': '',\n",
    "        'indent': 0,\n",
    "        'current': False\n",
    "    }\n",
    "\n",
    "    for section in record:\n",
    "\n",
    "        if section['htsno'] == '':\n",
    "\n",
    "            saved_section_description = {\n",
    "                'description': section['description'],\n",
    "                'indent': section['indent'],\n",
    "                'current': True\n",
    "            }\n",
    "            continue\n",
    "        \n",
    "        if saved_section_description['current'] == True:\n",
    "\n",
    "            if saved_section_description['indent'] == (section['indent'] -1):\n",
    "                section['description'] += f' | {saved_section_description['description']}'\n",
    "            \n",
    "            else:\n",
    "                saved_section_description['current'] = False\n",
    "\n",
    "        result.append(section)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createHTSDict(path: str):\n",
    "    \"\"\"Method that creates a dictionary object with all the HTS data from the CBP site in JSON format for all chapters.\n",
    "\n",
    "    Args:\n",
    "        path (str): Path of the original HTS JSON file downloaded from CBP\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary object with all the information in the original HTS file\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_json(path)\n",
    "    columns_df = df.columns.tolist()\n",
    "    final_dict = {}\n",
    "    main_numbers_pattern = re.compile(r'^[\\d]{4}')\n",
    "    start = True\n",
    "    current_main_hts = ['']\n",
    "    previous_main_hts = ['']\n",
    "\n",
    "    for index,row in df.iterrows():\n",
    "\n",
    "        current_main_hts = main_numbers_pattern.findall(row['htsno'])\n",
    "\n",
    "        if start:\n",
    "            previous_main_hts = current_main_hts\n",
    "            final_dict[current_main_hts[0]] = pd.DataFrame(columns=columns_df)\n",
    "            addRowsToDataframe(final_dict[current_main_hts[0]], row)\n",
    "\n",
    "        if len(current_main_hts) == 0:\n",
    "            current_main_hts = previous_main_hts\n",
    "\n",
    "        if (previous_main_hts[0] != current_main_hts[0]) and (len(current_main_hts)):\n",
    "            final_dict[current_main_hts[0]] = pd.DataFrame(columns=columns_df)\n",
    "            addRowsToDataframe(final_dict[current_main_hts[0]], row)\n",
    "            previous_main_hts = current_main_hts  \n",
    "        elif start == False:\n",
    "            addRowsToDataframe(final_dict[current_main_hts[0]], row)\n",
    "        start = False\n",
    "\n",
    "    return final_dict\n",
    "\n",
    "def writeFiles(HTS_dict: dict, path_hts: str, path_strings: str):\n",
    "    \"\"\"Writes all header sections of HTS codes into a single JSON file into a path_hts folder. And creates a single JSON file containing all keywords with lists of the HTS file names where they are located\n",
    "\n",
    "    Args:\n",
    "        HTS_dict (dict): HTS dictionary object with all the chapter information from CBP\n",
    "        path_hts (str): Path to store the individual HTS JSON files divided by header code\n",
    "        path_strings (str): Path to store the string dictionary into a JSON file\n",
    "    \"\"\"\n",
    "\n",
    "    string_dict = {}\n",
    "    file_dict = {}\n",
    "    file_path = 'string_dict.json'\n",
    "\n",
    "    for key,df in HTS_dict.items():\n",
    "        \n",
    "        file_dict[key] = f'{path_hts}/{key}.json'\n",
    "\n",
    "        df.to_json(file_dict[key], orient='records')\n",
    "\n",
    "        for row in df.iterrows():\n",
    "            desc = re.sub(pattern=punctuation_pattern, repl='', string=row[1]['description']).lower()\n",
    "            \n",
    "            array_string = desc.split()\n",
    "            \n",
    "            if(len(array_string) <= 0): continue\n",
    "            \n",
    "            for string in array_string:\n",
    "                if(checkKeyWords(string) == False): continue\n",
    "\n",
    "                if(string in string_dict):\n",
    "                    string_dict[string].append(key)\n",
    "                    string_dict[string] = list(set(string_dict[string]))\n",
    "                    continue\n",
    "            \n",
    "                string_dict[string] = []\n",
    "                string_dict[string].append(key)\n",
    "                string_dict[string] = list(set(string_dict[string]))\n",
    "\n",
    "    with open(f'{path_strings}{file_path}', 'w') as json_file:\n",
    "        json.dump(string_dict, json_file, indent=4)\n",
    "\n",
    "def removeEmptyHTS(folder: str):\n",
    "    \"\"\"Method that overwrites the already created json HTS files, processing them again so they are passed on without the empty \"htsno\" sections.\n",
    "\n",
    "    Args:\n",
    "        folder (str): Folder where the already processed json files are located\n",
    "    \"\"\"\n",
    "\n",
    "    filenames = os.listdir(folder)\n",
    "\n",
    "    for file in filenames:\n",
    "\n",
    "        record = openJSON(f'{folder}{file}')\n",
    "        processed_record = processRecord(record)\n",
    "\n",
    "        with open(f'{folder}{file}', 'w') as final_file:\n",
    "            json.dump(processed_record, final_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeFiles(createHTSDict('../db_hts/htsdata/htsdata.json'), '../db_hts/temp/NEW_test_files/', '../db_hts/temp/NEW_test_string_dict/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "removeEmptyHTS('../db_hts/temp/NEW_test_files/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
