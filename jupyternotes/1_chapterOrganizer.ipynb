{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains all the code for creating the HTS and string_dict files in the temp folder for further addition to the MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_words = [\"a\",\"about\",\"above\",\"after\",\"again\",\"against\",\"all\",\"am\",\"an\",\"and\",\"any\",\"are\",\"aren't\",\"as\",\"at\",\"be\",\"because\",\"been\",\"before\",\"being\",\"below\",\"between\",\"both\",\"but\",\"by\",\"can't\",\"cannot\",\"could\",\"couldn't\",\"did\",\"didn't\",\"do\",\"does\",\"doesn't\",\"doing\",\"don't\",\"down\",\"during\",\"each\",\"few\",\"for\",\"from\",\"further\",\"had\",\"hadn't\",\"has\",\"hasn't\",\"have\",\"haven't\",\"having\",\"he\",\"he'd\",\"he'll\",\"he's\",\"her\",\"here\",\"here's\",\"hers\",\"herself\",\"him\",\"himself\",\"his\",\"how\",\"how's\",\"i\",\"i'd\",\"i'll\",\"i'm\",\"i've\",\"if\",\"in\",\"into\",\"is\",\"isn't\",\"it\",\"it's\",\"its\",\"itself\",\"let's\",\"me\",\"more\",\"most\",\"mustn't\",\"my\",\"myself\",\"no\",\"nor\",\"not\",\"of\",\"off\",\"on\",\"once\",\"only\",\"or\",\"other\",\"ought\",\"our\",\"ours\",\"ourselves\",\"out\",\"over\",\"own\",\"same\",\"shan't\",\"she\",\"she'd\",\"she'll\",\"she's\",\"should\",\"shouldn't\",\"so\",\"some\",\"such\",\"than\",\"that\",\"that's\",\"the\",\"their\",\"theirs\",\"them\",\"themselves\",\"then\",\"there\",\"there's\",\"these\",\"they\",\"they'd\",\"they'll\",\"they're\",\"they've\",\"this\",\"those\",\"through\",\"to\",\"too\",\"under\",\"until\",\"up\",\"very\",\"was\",\"wasn't\",\"we\",\"we'd\",\"we'll\",\"we're\",\"we've\",\"were\",\"weren't\",\"what\",\"what's\",\"when\",\"when's\",\"where\",\"where's\",\"which\",\"while\",\"who\",\"who's\",\"whom\",\"why\",\"why's\",\"with\",\"won't\",\"would\",\"wouldn't\",\"you\",\"you'd\",\"you'll\",\"you're\",\"you've\",\"your\",\"yours\",\"yourself\",\"yourselves\"]\n",
    "\n",
    "punctuation_pattern = r'[!\\\"#$%&\\'()*+,-./:;<=>?@\\[\\]\\^_`{|}~â€”]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "\n",
    "def addRowsToDataframe(df: pd.DataFrame, row: list):\n",
    "    \"\"\"Helper method used to easily add new rows to a pandas dataframe\n",
    "\n",
    "    Args:\n",
    "        df: pandas.DataFrame\n",
    "            DataFrame to add the new rows to\n",
    "        row (list): List to be added as a row into the dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    df.loc[len(df)] = row\n",
    "\n",
    "def checkKeyWords(string: str) -> bool:\n",
    "    \"\"\"Checks against the keywords list for any matches in the string input\n",
    "\n",
    "    Args:\n",
    "        string (str): String that will be checked\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the string does not coincide with the list, False if there is a match\n",
    "    \"\"\"\n",
    "\n",
    "    for keyword in key_words:\n",
    "        match = re.search(rf'^{keyword}$', string=string)\n",
    "        if(match):\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def openJSON(path: str) -> list[dict, any]:\n",
    "    \"\"\"Function that opens a JSON file and returns that file as a list\n",
    "\n",
    "    Args:\n",
    "        path (str): Path to the JSON file\n",
    "\n",
    "    Returns:\n",
    "        list: Returns a list object with the JSON information\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path, 'r') as file:\n",
    "        result = json.loads(file.read())\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misc methods to display info at time of creation of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countDFLength(iterrows: list) -> int:\n",
    "    \"\"\"Counts the number of rows in the original htsdata.json file df\n",
    "\n",
    "    Args:\n",
    "        iterrows (list): List of rows from iterator for counting\n",
    "\n",
    "    Returns:\n",
    "        int: Number of rows of htsdata.json df\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for row in iterrows:\n",
    "        count += 1\n",
    "    \n",
    "    return count\n",
    "\n",
    "def HTSDictProgressCount(current: int, total: int) -> int:\n",
    "\n",
    "    return f'{int((current/total) * 100)}%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createHTSDict(path: str) -> dict[pd.DataFrame, any]:\n",
    "    \"\"\"Method that creates a dictionary object with all the HTS data from the CBP site in JSON format for all chapters.\n",
    "\n",
    "    Args:\n",
    "        path (str): Path of the original HTS JSON file downloaded from CBP\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary object with all the information in the original HTS file\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_json(path)\n",
    "    columns_df = df.columns.tolist()\n",
    "    final_dict = {}\n",
    "    main_numbers_pattern = re.compile(r'^[\\d]{4}')\n",
    "    start = True\n",
    "    current_main_hts = ['']\n",
    "    previous_main_hts = ['']\n",
    "    total_rows = countDFLength(df.iterrows())\n",
    "    current_row = 0\n",
    "\n",
    "    for index,row in df.iterrows():\n",
    "\n",
    "        current_main_hts = main_numbers_pattern.findall(row['htsno'])\n",
    "\n",
    "        if start:\n",
    "            previous_main_hts = current_main_hts\n",
    "            final_dict[current_main_hts[0]] = pd.DataFrame(columns=columns_df)\n",
    "            addRowsToDataframe(final_dict[current_main_hts[0]], row)\n",
    "\n",
    "        if len(current_main_hts) == 0:\n",
    "            current_main_hts = previous_main_hts\n",
    "\n",
    "        if (previous_main_hts[0] != current_main_hts[0]) and (len(current_main_hts)):\n",
    "            final_dict[current_main_hts[0]] = pd.DataFrame(columns=columns_df)\n",
    "            addRowsToDataframe(final_dict[current_main_hts[0]], row)\n",
    "            previous_main_hts = current_main_hts  \n",
    "        elif start == False:\n",
    "            addRowsToDataframe(final_dict[current_main_hts[0]], row)\n",
    "        start = False\n",
    "\n",
    "        current_row += 1\n",
    "        print(f'Progress creating dictionary {HTSDictProgressCount(current_row, total_rows)}', end='\\r')\n",
    "\n",
    "    return final_dict\n",
    "\n",
    "def writeFiles(HTS_dict: dict[pd.DataFrame, any], path_hts: str, path_strings: str):\n",
    "    \"\"\"Writes all header sections of HTS codes into a single JSON file into a path_hts folder. And creates a single JSON file containing all keywords with lists of the HTS file names where they are located\n",
    "\n",
    "    Args:\n",
    "        HTS_dict (dict): HTS dictionary object with all the chapter information from CBP\n",
    "        path_hts (str): Path to store the individual HTS JSON files divided by header code\n",
    "        path_strings (str): Path to store the string dictionary into a JSON file\n",
    "    \"\"\"\n",
    "\n",
    "    string_dict = {}\n",
    "    file_dict = {}\n",
    "    file_path = 'string_dict.json'\n",
    "\n",
    "    for key,df in HTS_dict.items():\n",
    "        \n",
    "        file_dict[key] = f'{path_hts}/{key}.json'\n",
    "\n",
    "        try:\n",
    "            df.to_json(file_dict[key], orient='records')\n",
    "            print(f'File {key}.json - written', end='\\r')\n",
    "        except Exception as e:\n",
    "            print(f'Error writing file {key}.json')\n",
    "            print(e)\n",
    "\n",
    "        for row in df.iterrows():\n",
    "            desc = re.sub(pattern=punctuation_pattern, repl='', string=row[1]['description']).lower()\n",
    "            \n",
    "            array_string = desc.split()\n",
    "            \n",
    "            if(len(array_string) <= 0): continue\n",
    "            \n",
    "            for string in array_string:\n",
    "                if(checkKeyWords(string) == False): continue\n",
    "\n",
    "                if(string in string_dict):\n",
    "                    string_dict[string].append(key)\n",
    "                    string_dict[string] = list(set(string_dict[string]))\n",
    "                    print(f'string_dict key \"{string}\" added chapter \"{key}\"', end='\\r')\n",
    "                    continue\n",
    "            \n",
    "                string_dict[string] = []\n",
    "                string_dict[string].append(key)\n",
    "                string_dict[string] = list(set(string_dict[string]))\n",
    "                print(f'string_dict added string \"{string}\" with chapter \"{key}\"', end='\\r')\n",
    "\n",
    "    with open(f'{path_strings}{file_path}', 'w') as json_file:\n",
    "        json.dump(string_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string_dict key \"subchapter\" added chapter \"9922\"apter \"9922\"7\"3\"\"\"\"9902\"2\"9902\"r \"9902\"\"902\"902\"9902\"2\"9902\"\r"
     ]
    }
   ],
   "source": [
    "writeFiles(createHTSDict('../db_hts/htsdata/htsdata.json'), '../db_hts/temp/NEW_test_files/', '../db_hts/temp/NEW_test_string_dict/')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
